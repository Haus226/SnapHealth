{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:33.253502Z",
     "iopub.status.busy": "2023-10-22T04:35:33.253094Z",
     "iopub.status.idle": "2023-10-22T04:35:43.487999Z",
     "shell.execute_reply": "2023-10-22T04:35:43.487041Z",
     "shell.execute_reply.started": "2023-10-22T04:35:33.253473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, test and validate images generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.490721Z",
     "iopub.status.busy": "2023-10-22T04:35:43.490195Z",
     "iopub.status.idle": "2023-10-22T04:35:43.503215Z",
     "shell.execute_reply": "2023-10-22T04:35:43.502048Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.490690Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateGenerator(path, batchSize):\n",
    "    base_path = path\n",
    "    print(\"\\nTotal : \", end=\" \")\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(batch_size=32, directory=base_path+\"/\"+\"train\")\n",
    "\n",
    "    train_datagen = ImageDataGenerator()\n",
    "\n",
    "    print(\"\\nFor Training : \", end=\" \")\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        base_path+\"/\"+\"train\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', subset='training')\n",
    "\n",
    "    print(\"\\nFor Val : \", end=\" \")\n",
    "    valid_datagen = ImageDataGenerator()\n",
    "    validation_generator = valid_datagen.flow_from_directory(\n",
    "        base_path+\"/\"+\"val\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',shuffle=False)\n",
    "    print(\"\\nFor Test : \", end=\" \")\n",
    "\n",
    "    test_datagen = ImageDataGenerator()\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        base_path+\"/\"+\"test\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', shuffle=False)\n",
    "    class_names = train_dataset.class_names\n",
    "    noOfClasses = len(class_names)\n",
    "    print(\"\\nNo of Classes : \", noOfClasses)\n",
    "    print(\"Classes : \", class_names)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in train_dataset.take(1):\n",
    "        for i in range(noOfClasses):\n",
    "            ax = plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(class_names[labels[i]])\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    for image_batch, labels_batch in train_dataset:\n",
    "        print(\"Image Shape : \",image_batch.shape)\n",
    "        break\n",
    "        \n",
    "    return noOfClasses,class_names, train_generator, validation_generator,test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our model\n",
    "- VGG-19\n",
    "- Xception\n",
    "- InceptionV3\n",
    "- DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.522195Z",
     "iopub.status.busy": "2023-10-22T04:35:43.521444Z",
     "iopub.status.idle": "2023-10-22T04:35:43.534406Z",
     "shell.execute_reply": "2023-10-22T04:35:43.533365Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.522158Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateVGG19(noOfClasses):\n",
    "    norm = layers.Rescaling(1./255, input_shape=IMAGE_SIZE + [3])\n",
    "    modelInput = tf.keras.applications.VGG19(\n",
    "        input_shape=IMAGE_SIZE + [3],\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    \n",
    "    for layer in modelInput.layers:\n",
    "        layer.trainable = False\n",
    "    model = keras.models.Sequential([\n",
    "        norm,\n",
    "        modelInput,\n",
    "        Flatten(),\n",
    "        Dense(noOfClasses, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def modelSummary(model):\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.537570Z",
     "iopub.status.busy": "2023-10-22T04:35:43.537248Z",
     "iopub.status.idle": "2023-10-22T04:35:43.546757Z",
     "shell.execute_reply": "2023-10-22T04:35:43.545813Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.537544Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateXception(noOfClasses):\n",
    "    norm = layers.Rescaling(1./255, input_shape=IMAGE_SIZE + [3])\n",
    "    modelInput = tf.keras.applications.Xception(\n",
    "        input_shape=IMAGE_SIZE + [3],\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    \n",
    "    for layer in modelInput.layers:\n",
    "        layer.trainable = False\n",
    "    model = keras.models.Sequential([\n",
    "        norm,\n",
    "        modelInput,\n",
    "        Flatten(),\n",
    "        Dense(noOfClasses, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.560356Z",
     "iopub.status.busy": "2023-10-22T04:35:43.559984Z",
     "iopub.status.idle": "2023-10-22T04:35:43.571373Z",
     "shell.execute_reply": "2023-10-22T04:35:43.570580Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.560332Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateInceptionV3(noOfClasses):\n",
    "    norm = layers.Rescaling(1./255, input_shape=IMAGE_SIZE + [3])\n",
    "    modelInput = tf.keras.applications.InceptionV3(\n",
    "        input_shape=IMAGE_SIZE + [3],\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    \n",
    "    for layer in modelInput.layers:\n",
    "        layer.trainable = False\n",
    "    model = keras.models.Sequential([\n",
    "        norm,\n",
    "        modelInput,\n",
    "        Flatten(),\n",
    "        Dense(noOfClasses, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.572870Z",
     "iopub.status.busy": "2023-10-22T04:35:43.572586Z",
     "iopub.status.idle": "2023-10-22T04:35:43.588128Z",
     "shell.execute_reply": "2023-10-22T04:35:43.586944Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.572846Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateDenseNet201(noOfClasses):\n",
    "    norm = layers.Rescaling(1./255, input_shape=IMAGE_SIZE + [3])\n",
    "    modelInput = tf.keras.applications.DenseNet201(\n",
    "        input_shape=IMAGE_SIZE + [3],\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    \n",
    "    for layer in modelInput.layers:\n",
    "        layer.trainable = False\n",
    "    model = keras.models.Sequential([\n",
    "        norm,\n",
    "        modelInput,\n",
    "        Flatten(),\n",
    "        Dense(noOfClasses, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations of\n",
    "- Optimizer\n",
    "- Loss function and metric\n",
    "- Learning rate scheduler\n",
    "- Checkpoint saving\n",
    "- Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.589805Z",
     "iopub.status.busy": "2023-10-22T04:35:43.589517Z",
     "iopub.status.idle": "2023-10-22T04:35:43.600722Z",
     "shell.execute_reply": "2023-10-22T04:35:43.599750Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.589780Z"
    }
   },
   "outputs": [],
   "source": [
    "def initiateParams(className, model, lr,model_name):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, min_lr=1e-5, mode=\"max\")\n",
    "    checkpoint = ModelCheckpoint(className + \"/\" + className + model_name + \"-{epoch:02d}-{val_accuracy:.3f}.h5\", verbose=2, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "    early = EarlyStopping(monitor=\"val_accuracy\", patience=3, verbose=1, mode=\"max\")\n",
    "    return model, annealer, early, checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.603944Z",
     "iopub.status.busy": "2023-10-22T04:35:43.603646Z",
     "iopub.status.idle": "2023-10-22T04:35:43.612893Z",
     "shell.execute_reply": "2023-10-22T04:35:43.611921Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.603918Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelFit(model, annealer, early, checkpoint, epochs=1, class_weight=None):\n",
    "\n",
    "    history = model.fit(\n",
    "      train_generator,\n",
    "      validation_data=validation_generator,\n",
    "      epochs=epochs,\n",
    "      callbacks=[annealer, early, checkpoint],\n",
    "      steps_per_epoch=len(train_generator),\n",
    "      validation_steps=len(validation_generator),\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the train and validate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.614418Z",
     "iopub.status.busy": "2023-10-22T04:35:43.614146Z",
     "iopub.status.idle": "2023-10-22T04:35:43.631578Z",
     "shell.execute_reply": "2023-10-22T04:35:43.630482Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.614393Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotOutput(history, className, modelName, epochs):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig(className + \"/\" + className + \"_\" + modelName + '_graph.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and Save the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.633776Z",
     "iopub.status.busy": "2023-10-22T04:35:43.633083Z",
     "iopub.status.idle": "2023-10-22T04:35:43.644456Z",
     "shell.execute_reply": "2023-10-22T04:35:43.643389Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.633722Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalModel(model):\n",
    "    evl = model.evaluate(test_generator)\n",
    "    acc = evl[1]*100\n",
    "    msg=f'Accuracy on the Test Set = {acc:5.2f} %'\n",
    "    print(msg)\n",
    "    return acc\n",
    "    \n",
    "def saveModel(model, className, model_name, acc):\n",
    "    model.save(className + \"/\" + className + \" - \"+ model_name + f\"_{acc:.3f}\" + \"Final.h5\")\n",
    "    print(f\"Final {model_name} model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weighted recall, precision, f1 and accuracy\n",
    "## Plot the confusion matrix\n",
    "## Plot the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.646050Z",
     "iopub.status.busy": "2023-10-22T04:35:43.645696Z",
     "iopub.status.idle": "2023-10-22T04:35:43.659373Z",
     "shell.execute_reply": "2023-10-22T04:35:43.658392Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.646019Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score, accuracy_score\n",
    "def callPlot(model, modelName, className, classes):\n",
    "    y_true = test_generator.classes\n",
    "    print(\"True : \", (y_true))\n",
    "\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    print(\"Predicted : \", (y_pred))\n",
    "    \n",
    "    recall=recall_score(y_true,y_pred,average='weighted')\n",
    "    p=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1=f1_score(y_true, y_pred,average='weighted')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"ACCURACY={acc}\")\n",
    "    print(f\"RECALL={recall}\")\n",
    "    print(f\"precision={p}\")\n",
    "    print(f\"F1 Score{f1}\")\n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    conf_df = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f\"{modelName}_{className}_{acc:.3f}\")\n",
    "    sns.heatmap(conf_df, annot=True, fmt=\"g\")\n",
    "    plt.savefig(className + \"/\" + className + \"_\" + modelName + f\"{acc:.3f}_confusionMatrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    report = {\n",
    "        c : 0 for c in classes\n",
    "    }\n",
    "    report.update(classification_report(y_true, y_pred, output_dict=True))\n",
    "    for idx, _ in enumerate(classes):\n",
    "        report[_] = report[f\"{idx}\"]\n",
    "        del report[f\"{idx}\"]\n",
    "    del report[\"accuracy\"]\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f\"{modelName}_{className}_{acc:.3f}\")\n",
    "    sns.heatmap(df, annot=True)\n",
    "    plt.savefig(className + \"/\" + className + \"_\" + modelName + f\"_{acc:.3f}_classificationReport.png\")\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model\n",
    "- Sum up the prediction from the models chose with weight (test accuracy)\n",
    "- Plot the confusion matrix\n",
    "- Plot the classification report\n",
    "- Normalization of the final prediction is carried out in the predict.py file so that user receive the probability between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.663042Z",
     "iopub.status.busy": "2023-10-22T04:35:43.662727Z",
     "iopub.status.idle": "2023-10-22T04:35:43.676517Z",
     "shell.execute_reply": "2023-10-22T04:35:43.675732Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.663016Z"
    }
   },
   "outputs": [],
   "source": [
    "def Ensemble(c, classes):\n",
    "    y_true = test_generator.classes\n",
    "    print(\"True : \", (y_true))\n",
    "    pred=[]\n",
    "    for model,obj in part[c]['models'].items():\n",
    "        pred.append(obj['model'].predict(test_generator) * obj[\"acc\"])\n",
    "    \n",
    "    y_pred = pred[0]\n",
    "    for i in range(1,len(pred)):\n",
    "        y_pred = y_pred + pred[i]\n",
    "        \n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    print(\"Predicted : \", (y_pred))\n",
    "\n",
    "    recall=recall_score(y_true,y_pred,average='weighted')\n",
    "    p=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1=f1_score(y_true, y_pred,average='weighted')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"ACCURACY={acc}\")\n",
    "    print(f\"RECALL={recall}\")\n",
    "    print(f\"precision={p}\")\n",
    "    print(f\"F1 Score{f1}\")\n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    conf_df = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f\"Ensemble_{className}_{acc:.3f}\")\n",
    "    sns.heatmap(conf_df, annot=True, fmt=\"g\")\n",
    "    plt.savefig(className + \"/\" + className + \"_\" + f\"Ensemble_{acc:.3f}_confusionMatrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    report = {\n",
    "        c : 0 for c in classes\n",
    "    }\n",
    "    report.update(classification_report(y_true, y_pred, output_dict=True))\n",
    "    for idx, _ in enumerate(classes):\n",
    "        report[_] = report[f\"{idx}\"]\n",
    "        del report[f\"{idx}\"]\n",
    "    del report[\"accuracy\"]\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f\"Ensemble_{className}_{acc:.3f}\")\n",
    "    sns.heatmap(df, annot=True)\n",
    "    plt.savefig(className + \"/\" + className + \"_\" + f\"Ensemble_{acc:.3f}_classificationReport.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the folder path and hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.677888Z",
     "iopub.status.busy": "2023-10-22T04:35:43.677573Z",
     "iopub.status.idle": "2023-10-22T04:35:43.693153Z",
     "shell.execute_reply": "2023-10-22T04:35:43.692305Z",
     "shell.execute_reply.started": "2023-10-22T04:35:43.677862Z"
    }
   },
   "outputs": [],
   "source": [
    "mpath = r'/kaggle/input/chest-xray-pneumoniacovid19tuberculosis'\n",
    "c = className = \"lung\"\n",
    "part={}\n",
    "part[c]={'models':{},'no_of_classes':0,\"ClassNames\":None} \n",
    "IMAGE_SIZE = [224, 224]\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "noOfClasses = 0\n",
    "gEpochs = 30\n",
    "lr = 0.001\n",
    "batchSize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate class weight to deal with class imbalance and train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T04:35:43.694901Z",
     "iopub.status.busy": "2023-10-22T04:35:43.694495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total :  Found 6326 files belonging to 4 classes.\n",
      "\n",
      "For Training :  Found 6326 images belonging to 4 classes.\n",
      "\n",
      "For Val :  Found 38 images belonging to 4 classes.\n",
      "Found 771 images belonging to 4 classes.\n",
      "\n",
      "No of Classes :  4\n",
      "Classes :  ['COVID19', 'NORMAL', 'PNEUMONIA', 'TURBERCULOSIS']\n",
      "Image Shape :  (32, 256, 256, 3)\n",
      "######################################################\n",
      "RESULTS FORVGG-19\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8824\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89474, saving model to lung/lungVGG-19-01-0.895.h5\n",
      "198/198 [==============================] - 130s 592ms/step - loss: 0.3667 - accuracy: 0.8824 - val_loss: 0.2344 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9581\n",
      "Epoch 2: val_accuracy improved from 0.89474 to 0.94737, saving model to lung/lungVGG-19-02-0.947.h5\n",
      "198/198 [==============================] - 74s 373ms/step - loss: 0.1081 - accuracy: 0.9581 - val_loss: 0.0724 - val_accuracy: 0.9474 - lr: 0.0010\n",
      "Epoch 3/30\n",
      " 43/198 [=====>........................] - ETA: 59s - loss: 0.0801 - accuracy: 0.9709"
     ]
    }
   ],
   "source": [
    "className = c\n",
    "noOfClasses, class_names, train_generator, validation_generator, test_generator = initiateGenerator(mpath, batchSize=batchSize)\n",
    "part[c]['ClassNames'] = class_names\n",
    "\n",
    "class_weight = class_weight.compute_class_weight(\n",
    "               class_weight='balanced',\n",
    "                classes=np.unique(train_generator.classes), \n",
    "                y=train_generator.classes)\n",
    "class_weight = {x : class_weight[x] for x in range(len(class_weight))}\n",
    "\n",
    "model_name=\"VGG-19\"\n",
    "print(\"######################################################\")\n",
    "print(f\"RESULTS FOR{model_name}\")\n",
    "curVGG19 = initiateVGG19(noOfClasses)\n",
    "curVGG19, annealer, early, checkpoint = initiateParams(className, curVGG19, lr,model_name)\n",
    "curHistory = modelFit(curVGG19, annealer, early, checkpoint, epochs=gEpochs, class_weight=class_weight)\n",
    "plotOutput(curHistory, className, model_name, gEpochs)\n",
    "acc=evalModel(curVGG19)\n",
    "\n",
    "saveModel(curVGG19, className, model_name, acc)\n",
    "part[c]['models'][model_name]={\"model\":curVGG19,'acc':acc}\n",
    "callPlot(curVGG19, model_name, className, class_names)\n",
    "\n",
    "model_name=\"Xception\"\n",
    "print(\"######################################################\")\n",
    "print(f\"RESULTS FOR{model_name}\")\n",
    "curXception= initiateXception(noOfClasses)\n",
    "curXception, annealer, early, checkpoint = initiateParams(className, curXception, lr,model_name)\n",
    "curHistory = modelFit(curXception, annealer, early, checkpoint, epochs=gEpochs, class_weight=class_weight)\n",
    "plotOutput(curHistory, className, model_name, gEpochs)\n",
    "acc=evalModel(curXception)\n",
    "saveModel(curXception, className, model_name, acc)\n",
    "part[c]['models'][model_name]={\"model\":curXception,'acc':acc}\n",
    "callPlot(curXception, model_name, className, class_names)\n",
    "\n",
    "model_name=\"InceptionV3\"\n",
    "print(\"######################################################\")\n",
    "print(f\"RESULTS FOR{model_name}\")\n",
    "curInceptionV3 = initiateInceptionV3(noOfClasses)\n",
    "#modelSummary(curInceptionV3)\n",
    "curInceptionV3, annealer, early, checkpoint = initiateParams(className, curInceptionV3, lr,model_name)\n",
    "curHistory = modelFit(curInceptionV3, annealer, early, checkpoint, epochs=gEpochs, class_weight=class_weight)\n",
    "plotOutput(curHistory, className, model_name, gEpochs)\n",
    "acc=evalModel(curInceptionV3)\n",
    "saveModel(curInceptionV3, className, model_name, acc)\n",
    "part[c]['models'][model_name]={\"model\":curInceptionV3,'acc':acc}\n",
    "callPlot(curInceptionV3, model_name, className, class_names)\n",
    "\n",
    "model_name=\"DenseNet201\"\n",
    "print(\"######################################################\")\n",
    "print(f\"RESULTS FOR{model_name}\")\n",
    "curDenseNet201= initiateDenseNet201(noOfClasses)\n",
    "curDenseNet201, annealer, early, checkpoint = initiateParams(className, curDenseNet201, lr,model_name)\n",
    "curHistory = modelFit(curDenseNet201, annealer, early, checkpoint, epochs=gEpochs, class_weight=class_weight)\n",
    "plotOutput(curHistory, className, model_name, gEpochs)\n",
    "acc=evalModel(curDenseNet201)\n",
    "saveModel(curDenseNet201, className, model_name, acc)\n",
    "part[c]['models'][model_name]={\"model\":curDenseNet201,'acc':acc}\n",
    "callPlot(curDenseNet201, model_name, className, class_names)\n",
    "\n",
    "print(\"######################################################\")\n",
    "print(f\"RESULTS FOR ENSEMBLE\")\n",
    "Ensemble(c, class_names)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
